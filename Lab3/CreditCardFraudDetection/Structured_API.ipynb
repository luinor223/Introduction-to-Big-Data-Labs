{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/04 18:10:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting Spark log level to \"ERROR\".\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"credit-card-fraud-detection\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.log.level\", \"ERROR\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-------------------+----------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------+-----+\n",
      "|Time|                V1|                 V2|              V3|                V4|                 V5|                 V6|                 V7|                V8|                V9|                V10|               V11|               V12|               V13|               V14|               V15|               V16|               V17|                V18|               V19|                V20|                 V21|                V22|               V23|               V24|               V25|               V26|                 V27|                V28|Amount|Class|\n",
      "+----+------------------+-------------------+----------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------+-----+\n",
      "| 0.0|  -1.3598071336738|-0.0727811733098497|2.53634673796914|  1.37815522427443| -0.338320769942518|  0.462387777762292|  0.239598554061257|0.0986979012610507| 0.363786969611213| 0.0907941719789316|-0.551599533260813|-0.617800855762348|-0.991389847235408|-0.311169353699879|  1.46817697209427|-0.470400525259478| 0.207971241929242| 0.0257905801985591| 0.403992960255733|  0.251412098239705|  -0.018306777944153|  0.277837575558899|-0.110473910188767|0.0669280749146731| 0.128539358273528|-0.189114843888824|   0.133558376740387|-0.0210530534538215|149.62|    0|\n",
      "| 0.0|  1.19185711131486|   0.26615071205963|0.16648011335321| 0.448154078460911| 0.0600176492822243|-0.0823608088155687|-0.0788029833323113|0.0851016549148104|-0.255425128109186| -0.166974414004614|  1.61272666105479|  1.06523531137287|  0.48909501589608|-0.143772296441519| 0.635558093258208| 0.463917041022171|-0.114804663102346| -0.183361270123994|-0.145783041325259|-0.0690831352230203|  -0.225775248033138| -0.638671952771851| 0.101288021253234|-0.339846475529127| 0.167170404418143| 0.125894532368176|-0.00898309914322813| 0.0147241691924927|  2.69|    0|\n",
      "| 1.0| -1.35835406159823|  -1.34016307473609|1.77320934263119| 0.379779593034328| -0.503198133318193|   1.80049938079263|  0.791460956450422| 0.247675786588991| -1.51465432260583|  0.207642865216696| 0.624501459424895| 0.066083685268831| 0.717292731410831|-0.165945922763554|  2.34586494901581| -2.89008319444231|  1.10996937869599| -0.121359313195888| -2.26185709530414|  0.524979725224404|   0.247998153469754|  0.771679401917229| 0.909412262347719|-0.689280956490685|-0.327641833735251|-0.139096571514147| -0.0553527940384261|-0.0597518405929204|378.66|    0|\n",
      "| 1.0|-0.966271711572087| -0.185226008082898|1.79299333957872|-0.863291275036453|-0.0103088796030823|   1.24720316752486|   0.23760893977178| 0.377435874652262| -1.38702406270197|-0.0549519224713749|-0.226487263835401| 0.178228225877303| 0.507756869957169| -0.28792374549456|-0.631418117709045|  -1.0596472454325|-0.684092786345479|   1.96577500349538|  -1.2326219700892| -0.208037781160366|  -0.108300452035545|0.00527359678253453|-0.190320518742841| -1.17557533186321| 0.647376034602038|-0.221928844458407|  0.0627228487293033| 0.0614576285006353| 123.5|    0|\n",
      "| 2.0| -1.15823309349523|  0.877736754848451|  1.548717846511| 0.403033933955121| -0.407193377311653| 0.0959214624684256|  0.592940745385545|-0.270532677192282| 0.817739308235294|  0.753074431976354|-0.822842877946363|  0.53819555014995|   1.3458515932154| -1.11966983471731| 0.175121130008994|-0.451449182813529|-0.237033239362776|-0.0381947870352842| 0.803486924960175|  0.408542360392758|-0.00943069713232919|   0.79827849458971|-0.137458079619063| 0.141266983824769|-0.206009587619756| 0.502292224181569|   0.219422229513348|  0.215153147499206| 69.99|    0|\n",
      "+----+------------------+-------------------+----------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change the path to the CSV file as needed\n",
    "# Load the dataset\n",
    "df = spark.read.csv(\"../../data/creditcard.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the data**:\n",
    "- According to the dataset description, the input variables are the result of a PCA transformation except \"Time\" and \"Amount\" so the features are previously scaled. \n",
    "- Every value in the dataset is not null so imputing is also not needed.\n",
    "- The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. To deal with this problem, we have 2 methods:\n",
    "    - Cost-sensitive learning: the lost function will be adjusted to favor the detection of the minority class.\n",
    "    - Undersampling, oversampling technique or a combination of the two.\n",
    "\n",
    "Because of the reasons above and the fact that I will choose the oversampling method to deal with the highly unbalanced nature of the dataset, this data processing step will include:\n",
    "- Using the VectorAssembler class to assemble feature columns into a single vector column\n",
    "- Splitting the dataset into train and test set.\n",
    "- Oversample the minority class (Class = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all columns as features exclude the target column \"Class\"\n",
    "input_cols = df.columns[:-1]\n",
    "\n",
    "# Assemble the features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "df = df.select(\"features\", \"Class\")\n",
    "\n",
    "# Sample training data in a stratified fashion\n",
    "train_df = df.sampleBy(\"Class\", {1: 0.8, 0: 0.8}, seed=42)\n",
    "\n",
    "# Get test data as the remaining set\n",
    "test_df = df.subtract(train_df)\n",
    "\n",
    "# Oversample the train df to deal with class imbalance\n",
    "# Calculate class counts in the training data\n",
    "class_counts = train_df.groupBy(\"Class\").count().orderBy(\"Class\").collect()\n",
    "major_count, minor_count = class_counts[0][\"count\"], class_counts[1][\"count\"]\n",
    "# Calculate the desired oversampling ratio\n",
    "ratio = float(major_count) / minor_count\n",
    "# Filter out and oversample the minor class \n",
    "oversampled_minor_df = train_df\\\n",
    "    .filter(col(\"Class\") == 1)\\\n",
    "    .sample(withReplacement=True, fraction=ratio, seed=42)\n",
    "# Combine the minor with the train df\n",
    "train_df = train_df\\\n",
    "    .filter(col(\"Class\") == 0)\\\n",
    "    .union(oversampled_minor_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Logistic Regression model using spark.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression estimator\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"Class\"\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the obtained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-1.131150420707179e-05,1.057343270993391,0.3726135010612134,0.3620435935055492,0.9924165512574527,0.8688846837840881,-0.5486702501623859,-0.9353033108022877,-0.5086026586043687,-0.9158343014053011,-1.7511583070834809,0.4169357993180848,-1.1642091836545314,-0.378806834363519,-1.5138740153526984,-0.2286640729742732,-1.027760150276896,-1.259161622903398,-0.24461334898764917,0.6517688191295719,-1.5802257522464103,0.27557562031260224,0.9167827623508933,0.49406386921421513,-0.3412548036683508,-0.1574882489344699,-0.37249827969853955,-1.4041020959078092,0.25943816815868576,0.009981771497433184]\n",
      "Intercept: -3.7249811097894465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.950619449621752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.9888892389587758\n",
      "Precision: [0.9281903689336587, 0.9754790689073299]\n",
      "Recall: [0.976719790372773, 0.9245630255414803]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients:\", model.coefficients)\n",
    "print(\"Intercept:\", model.intercept)\n",
    "\n",
    "summary = model.summary\n",
    "print(\"Accuracy:\", summary.accuracy)\n",
    "print(\"Area under ROC:\", summary.areaUnderROC)\n",
    "print(\"Precision:\", summary.precisionByLabel)\n",
    "print(\"Recall:\", summary.recallByLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9769368920817255\n",
      "Area under ROC: 0.9703390050646288\n",
      "Area under PR: 0.7173733707071455\n",
      "Precision: [0.9998541742617572, 0.06390704429920116]\n",
      "Recall: [0.9770399529755437, 0.9166666666666666]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Class\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# AUC-ROC and AUC-PR\n",
    "binary_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Class\",\n",
    "    rawPredictionCol=\"rawPrediction\"\n",
    ")\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = [evaluator.evaluate(predictions, {evaluator.metricName: \"precisionByLabel\", evaluator.metricLabel: 0.0}),\n",
    "             evaluator.evaluate(predictions, {evaluator.metricName: \"precisionByLabel\", evaluator.metricLabel: 1.0})]\n",
    "recall = [evaluator.evaluate(predictions, {evaluator.metricName: \"recallByLabel\", evaluator.metricLabel: 0.0}),\n",
    "        evaluator.evaluate(predictions, {evaluator.metricName: \"recallByLabel\", evaluator.metricLabel: 1.0})]\n",
    "auc_roc = binary_evaluator.evaluate(predictions, {binary_evaluator.metricName: \"areaUnderROC\"})\n",
    "auc_pr = binary_evaluator.evaluate(predictions, {binary_evaluator.metricName: \"areaUnderPR\"})\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Area under ROC:\", auc_roc)\n",
    "print(\"Area under PR:\", auc_pr)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
